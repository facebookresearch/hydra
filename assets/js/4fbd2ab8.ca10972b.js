"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3934],{15680:(e,n,a)=>{a.r(n),a.d(n,{MDXContext:()=>m,MDXProvider:()=>c,mdx:()=>g,useMDXComponents:()=>s,withMDXComponents:()=>p});var r=a(96540);function t(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function l(){return l=Object.assign||function(e){for(var n=1;n<arguments.length;n++){var a=arguments[n];for(var r in a)Object.prototype.hasOwnProperty.call(a,r)&&(e[r]=a[r])}return e},l.apply(this,arguments)}function i(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?i(Object(a),!0).forEach((function(n){t(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function d(e,n){if(null==e)return{};var a,r,t=function(e,n){if(null==e)return{};var a,r,t={},l=Object.keys(e);for(r=0;r<l.length;r++)a=l[r],n.indexOf(a)>=0||(t[a]=e[a]);return t}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(r=0;r<l.length;r++)a=l[r],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(t[a]=e[a])}return t}var m=r.createContext({}),p=function(e){return function(n){var a=s(n.components);return r.createElement(e,l({},n,{components:a}))}},s=function(e){var n=r.useContext(m),a=n;return e&&(a="function"==typeof e?e(n):o(o({},n),e)),a},c=function(e){var n=s(e.components);return r.createElement(m.Provider,{value:n},e.children)},u="mdxType",y={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},h=r.forwardRef((function(e,n){var a=e.components,t=e.mdxType,l=e.originalType,i=e.parentName,m=d(e,["components","mdxType","originalType","parentName"]),p=s(a),c=t,u=p["".concat(i,".").concat(c)]||p[c]||y[c]||l;return a?r.createElement(u,o(o({ref:n},m),{},{components:a})):r.createElement(u,o({ref:n},m))}));function g(e,n){var a=arguments,t=n&&n.mdxType;if("string"==typeof e||t){var l=a.length,i=new Array(l);i[0]=h;var o={};for(var d in n)hasOwnProperty.call(n,d)&&(o[d]=n[d]);o.originalType=e,o[u]="string"==typeof e?e:t,i[1]=o;for(var m=2;m<l;m++)i[m]=a[m];return r.createElement.apply(null,i)}return r.createElement.apply(null,a)}h.displayName="MDXCreateElement"},39084:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>m,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>d,toc:()=>p});var r=a(58168),t=(a(96540),a(15680)),l=a(49595);const i={id:"ray_launcher",title:"Ray Launcher plugin",sidebar_label:"Ray Launcher plugin"},o=void 0,d={unversionedId:"plugins/ray_launcher",id:"plugins/ray_launcher",title:"Ray Launcher plugin",description:"PyPI",source:"@site/docs/plugins/ray_launcher.md",sourceDirName:"plugins",slug:"/plugins/ray_launcher",permalink:"/docs/plugins/ray_launcher",draft:!1,editUrl:"https://github.com/facebookresearch/hydra/edit/main/website/docs/plugins/ray_launcher.md",tags:[],version:"current",lastUpdatedBy:"jesszzzz",lastUpdatedAt:1741962216,formattedLastUpdatedAt:"Mar 14, 2025",frontMatter:{id:"ray_launcher",title:"Ray Launcher plugin",sidebar_label:"Ray Launcher plugin"},sidebar:"docs",previous:{title:"Joblib Launcher plugin",permalink:"/docs/plugins/joblib_launcher"},next:{title:"RQ Launcher plugin",permalink:"/docs/plugins/rq_launcher"}},m={},p=[{value:"Installation",id:"installation",level:3},{value:"Usage",id:"usage",level:3},{value:"<code>ray_aws</code> launcher",id:"ray_aws-launcher",level:3},{value:"Examples",id:"examples",level:4},{value:"Manage Cluster LifeCycle",id:"manage-cluster-lifecycle",level:5},{value:"Configure Ray Logging",id:"configure-ray-logging",level:5},{value:"<code>ray</code> launcher",id:"ray-launcher",level:3},{value:"Configure <code>ray.init()</code> and <code>ray.remote()</code>",id:"configure-rayinit-and-rayremote",level:3}],s={toc:p},c="wrapper";function u(e){let{components:n,...a}=e;return(0,t.mdx)(c,(0,r.A)({},s,a,{components:n,mdxType:"MDXLayout"}),(0,t.mdx)("p",null,(0,t.mdx)("a",{parentName:"p",href:"https://pypi.org/project/hydra-ray-launcher/"},(0,t.mdx)("img",{parentName:"a",src:"https://img.shields.io/pypi/v/hydra-ray-launcher",alt:"PyPI"})),"\n",(0,t.mdx)("img",{parentName:"p",src:"https://img.shields.io/pypi/l/hydra-ray-launcher",alt:"PyPI - License"}),"\n",(0,t.mdx)("img",{parentName:"p",src:"https://img.shields.io/pypi/pyversions/hydra-ray-launcher",alt:"PyPI - Python Version"}),"\n",(0,t.mdx)("a",{parentName:"p",href:"https://pypistats.org/packages/hydra-ray-launcher"},(0,t.mdx)("img",{parentName:"a",src:"https://img.shields.io/pypi/dm/hydra-ray-launcher.svg",alt:"PyPI - Downloads"})),(0,t.mdx)(l.C,{text:"Example application",to:"plugins/hydra_ray_launcher/examples",mdxType:"ExampleGithubLink"}),(0,t.mdx)(l.C,{text:"Plugin source",to:"plugins/hydra_ray_launcher",mdxType:"ExampleGithubLink"})),(0,t.mdx)("p",null,"The Ray Launcher plugin provides 2 launchers: ",(0,t.mdx)("inlineCode",{parentName:"p"},"ray_aws")," and ",(0,t.mdx)("inlineCode",{parentName:"p"},"ray"),".\n",(0,t.mdx)("inlineCode",{parentName:"p"},"ray_aws")," launches jobs remotely on AWS and is built on top of ",(0,t.mdx)("a",{parentName:"p",href:"https://docs.ray.io/en/releases-1.3.0/cluster/sdk.html"},"ray autoscaler sdk"),". ",(0,t.mdx)("inlineCode",{parentName:"p"},"ray")," launches jobs on your local machine or existing ray cluster. "),(0,t.mdx)("h3",{id:"installation"},"Installation"),(0,t.mdx)("pre",null,(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"$ pip install hydra-ray-launcher --upgrade\n")),(0,t.mdx)("h3",{id:"usage"},"Usage"),(0,t.mdx)("p",null,"Once installed, add ",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra/launcher=ray_aws")," or ",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra/launcher=ray")," to your command line. Alternatively, override ",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra/launcher")," in your config:"),(0,t.mdx)("pre",null,(0,t.mdx)("code",{parentName:"pre",className:"language-yaml"},"defaults:\n  - override hydra/launcher: ray_aws\n")),(0,t.mdx)("p",null,"There are several standard approaches for configuring plugins. Check ",(0,t.mdx)("a",{parentName:"p",href:"/docs/patterns/configuring_plugins"},"this page")," for more information."),(0,t.mdx)("h3",{id:"ray_aws-launcher"},(0,t.mdx)("inlineCode",{parentName:"h3"},"ray_aws")," launcher"),(0,t.mdx)("admonition",{type:"important"},(0,t.mdx)("p",{parentName:"admonition"},(0,t.mdx)("inlineCode",{parentName:"p"},"ray_aws")," launcher is built on top of ray's ",(0,t.mdx)("a",{parentName:"p",href:"https://docs.ray.io/en/releases-1.3.0/cluster/sdk.html"},"autoscaler sdk"),". To get started, you need to\n",(0,t.mdx)("a",{parentName:"p",href:"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html"},"config your AWS credentials"),".\n",(0,t.mdx)("inlineCode",{parentName:"p"},"ray autoscaler sdk")," expects your AWS credentials have certain permissions for ",(0,t.mdx)("a",{parentName:"p",href:"https://aws.amazon.com/ec2"},(0,t.mdx)("inlineCode",{parentName:"a"},"EC2"))," and ",(0,t.mdx)("a",{parentName:"p",href:"https://aws.amazon.com/iam"},(0,t.mdx)("inlineCode",{parentName:"a"},"IAM")),". Read ",(0,t.mdx)("a",{parentName:"p",href:"https://github.com/ray-project/ray/issues/9327"},"this")," for more information.")),(0,t.mdx)("p",null,(0,t.mdx)("inlineCode",{parentName:"p"},"ray autoscaler sdk")," expects a configuration for the EC2 cluster; we've schematized the configs in ",(0,t.mdx)(l.A,{to:"plugins/hydra_ray_launcher/hydra_plugins/hydra_ray_launcher/_config.py",mdxType:"GithubLink"},"here")),(0,t.mdx)("details",null,(0,t.mdx)("summary",null,"Discover ray_aws launcher's config"),(0,t.mdx)("pre",null,(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"$ python my_app.py hydra/launcher=ray_aws --cfg hydra -p hydra.launcher\n# @package hydra.launcher\n# @package hydra.launcher\n_target_: hydra_plugins.hydra_ray_launcher.ray_aws_launcher.RayAWSLauncher\nenv_setup:\n  pip_packages:\n    omegaconf: ${ray_pkg_version:omegaconf}\n    hydra_core: ${ray_pkg_version:hydra}\n    ray: ${ray_pkg_version:ray}\n    cloudpickle: ${ray_pkg_version:cloudpickle}\n    pickle5: 0.0.11\n    hydra_ray_launcher: 1.2.0.dev1\n  commands:\n  - conda create -n hydra_${python_version:micro} python=${python_version:micro} -y\n  - echo 'export PATH=\"$HOME/anaconda3/envs/hydra_${python_version:micro}/bin:$PATH\"'\n    >> ~/.bashrc\nray:\n  init:\n    address: null\n  remote: {}\n  cluster:\n    cluster_name: default\n    min_workers: 0\n    upscaling_speed: 1.0\n    max_workers: 1\n    initial_workers: 0\n    autoscaling_mode: default\n    target_utilization_fraction: 0.8\n    idle_timeout_minutes: 5\n    docker:\n      image: ''\n      container_name: ''\n      pull_before_run: true\n      run_options: []\n    provider:\n      type: aws\n      region: us-west-2\n      availability_zone: us-west-2a,us-west-2b\n      cache_stopped_nodes: false\n      key_pair:\n        key_name: hydra-${oc.env:USER,user}\n    auth:\n      ssh_user: ubuntu\n    available_node_types:\n      ray.head.default:\n        resources: {}\n        node_config:\n          InstanceType: m5.large\n          ImageId: ami-0a2363a9cff180a64\n      ray.worker.default:\n        min_workers: 0\n        max_workers: 2\n        resources: {}\n        node_config:\n          InstanceType: m5.large\n          ImageId: ami-0a2363a9cff180a64\n          InstanceMarketOptions:\n            MarketType: spot\n    head_node_type: ray.head.default\n    file_mounts: {}\n    initialization_commands: []\n    cluster_synced_files: []\n    setup_commands: []\n    head_setup_commands: []\n    worker_setup_commands: []\n    head_start_ray_commands:\n    - ray stop\n    - ulimit -n 65536;ray start --head --port=6379 --object-manager-port=8076             --autoscaling-config=~/ray_bootstrap_config.yaml\n    worker_start_ray_commands:\n    - ray stop\n    - ulimit -n 65536; ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076\n  run_env: auto\nstop_cluster: true\nsync_up:\n  source_dir: null\n  target_dir: null\n  include: []\n  exclude: []\nsync_down:\n  source_dir: null\n  target_dir: null\n  include: []\n  exclude: []\nlogging:\n  log_style: auto\n  color_mode: auto\n  verbosity: 0\ncreate_update_cluster:\n  no_restart: false\n  restart_only: false\n  no_config_cache: false\nteardown_cluster:\n  workers_only: false\n  keep_min_workers: false\n"))),(0,t.mdx)("h4",{id:"examples"},"Examples"),(0,t.mdx)("p",null,"The following examples can be found ",(0,t.mdx)(l.A,{to:"plugins/hydra_ray_launcher/examples",mdxType:"GithubLink"},"here"),"."),(0,t.mdx)("details",null,(0,t.mdx)("summary",null,"Simple app"),(0,t.mdx)("pre",null,(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"$ python my_app.py --multirun task=1,2,3\n[HYDRA] Ray Launcher is launching 3 jobs, \n[HYDRA]        #0 : task=1\n[HYDRA]        #1 : task=2\n[HYDRA]        #2 : task=3\n[HYDRA] Pickle for jobs: /var/folders/n_/9qzct77j68j6n9lh0lw3vjqcn96zxl/T/tmpqqg4v4i7/job_spec.pkl\nCluster: default\n...\nINFO services.py:1172 -- View the Ray dashboard at http://localhost:8265\n(pid=3374) [__main__][INFO] - Executing task 1\n(pid=3374) [__main__][INFO] - Executing task 2\n(pid=3374) [__main__][INFO] - Executing task 3\n...\n[HYDRA] Stopping cluster now. (stop_cluster=true)\n[HYDRA] Deleted the cluster (provider.cache_stopped_nodes=false)\nDestroying cluster. Confirm [y/N]: y [automatic, due to --yes]\n...\nNo nodes remaining.\n\n"))),(0,t.mdx)("details",null,(0,t.mdx)("summary",null,"Upload & Download from remote cluster"),(0,t.mdx)("p",null,"If your application is dependent on multiple modules, you can configure ",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra.launcher.sync_up")," to upload dependency modules to the remote cluster.\nYou can also configure ",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra.launcher.sync_down")," to download output from remote cluster if needed. This functionality is built on top of ",(0,t.mdx)("inlineCode",{parentName:"p"},"rsync"),", ",(0,t.mdx)("inlineCode",{parentName:"p"},"include")," and ",(0,t.mdx)("inlineCode",{parentName:"p"},"exclude")," is consistent with how it works in ",(0,t.mdx)("inlineCode",{parentName:"p"},"rsync"),"."),(0,t.mdx)("pre",null,(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"$  python train.py --multirun random_seed=1,2,3\n[HYDRA] Ray Launcher is launching 3 jobs, \n[HYDRA]        #0 : random_seed=1\n[HYDRA]        #1 : random_seed=2\n[HYDRA]        #2 : random_seed=3\n[HYDRA] Pickle for jobs: /var/folders/n_/9qzct77j68j6n9lh0lw3vjqcn96zxl/T/tmptdkye9of/job_spec.pkl\nCluster: default\n...\nINFO services.py:1172 -- View the Ray dashboard at http://localhost:8265\n(pid=1772) [__main__][INFO] - Start training...\n(pid=1772) [INFO] - Init my model\n(pid=1772) [INFO] - Created dir for checkpoints. dir=checkpoint\n(pid=1772) [__main__][INFO] - Start training...\n(pid=1772) [INFO] - Init my model\n(pid=1772) [INFO] - Created dir for checkpoints. dir=checkpoint\n(pid=1772) [__main__][INFO] - Start training...\n(pid=1772) [INFO] - Init my model\n(pid=1772) [INFO] - Created dir for checkpoints. dir=checkpoint\nLoaded cached provider configuration\n...\n[HYDRA] Output: receiving file list ... done\n16-32-25/\n16-32-25/0/\n16-32-25/0/checkpoint/\n16-32-25/0/checkpoint/checkpoint_1.pt\n16-32-25/1/\n16-32-25/1/checkpoint/\n16-32-25/1/checkpoint/checkpoint_2.pt\n16-32-25/2/\n16-32-25/2/checkpoint/\n16-32-25/2/checkpoint/checkpoint_3.pt\n...\n[HYDRA] Stopping cluster now. (stop_cluster=true)\n[HYDRA] Deleted the cluster (provider.cache_stopped_nodes=false)\nDestroying cluster. Confirm [y/N]: y [automatic, due to --yes]\n...\nNo nodes remaining.\n\n"))),(0,t.mdx)("h5",{id:"manage-cluster-lifecycle"},"Manage Cluster LifeCycle"),(0,t.mdx)("p",null,"You can manage the Ray EC2 cluster lifecycle by configuring the flags provided by the plugin:"),(0,t.mdx)("ul",null,(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Default setting (no need to specify on commandline): delete cluster after job finishes remotely:"),(0,t.mdx)("pre",{parentName:"li"},(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"hydra.launcher.stop_cluster=true\nhydra.launcher.ray.cluster.provider.cache_stopped_nodes=false\nhydra.launcher.teardown_cluster.workers_only=false\nhydra.launcher.teardown_cluster.keep_min_workers=false\n"))),(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Keep cluster running after jobs finishes remotely"),(0,t.mdx)("pre",{parentName:"li"},(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"hydra.launcher.stop_cluster=false\n"))),(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Power off EC2 instances and control node termination using ",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra.launcher.ray.cluster.provider.cache_stopped_nodes"),"\nand ",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra.launcher.teardown_cluster.workers_only")),(0,t.mdx)("table",{parentName:"li"},(0,t.mdx)("thead",{parentName:"table"},(0,t.mdx)("tr",{parentName:"thead"},(0,t.mdx)("th",{parentName:"tr",align:null},"cache_stopped_nodes"),(0,t.mdx)("th",{parentName:"tr",align:null},"workers_only"),(0,t.mdx)("th",{parentName:"tr",align:null},"behavior"))),(0,t.mdx)("tbody",{parentName:"table"},(0,t.mdx)("tr",{parentName:"tbody"},(0,t.mdx)("td",{parentName:"tr",align:null},"false"),(0,t.mdx)("td",{parentName:"tr",align:null},"false"),(0,t.mdx)("td",{parentName:"tr",align:null},"All nodes are terminated")),(0,t.mdx)("tr",{parentName:"tbody"},(0,t.mdx)("td",{parentName:"tr",align:null},"false"),(0,t.mdx)("td",{parentName:"tr",align:null},"true"),(0,t.mdx)("td",{parentName:"tr",align:null},"Keeps head node running and terminates only worker node")),(0,t.mdx)("tr",{parentName:"tbody"},(0,t.mdx)("td",{parentName:"tr",align:null},"true"),(0,t.mdx)("td",{parentName:"tr",align:null},"false"),(0,t.mdx)("td",{parentName:"tr",align:null},"Keeps both head node and worker node and stops both of them")),(0,t.mdx)("tr",{parentName:"tbody"},(0,t.mdx)("td",{parentName:"tr",align:null},"true"),(0,t.mdx)("td",{parentName:"tr",align:null},"true"),(0,t.mdx)("td",{parentName:"tr",align:null},"Keeps both head node and worker node and stops only worker node"))))),(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Keep ",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra.launcher.ray.cluster.min_workers")," worker nodes\nand delete the rest of the worker nodes"),(0,t.mdx)("pre",{parentName:"li"},(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"hydra.launcher.teardown_cluster.keep_min_workers=true\n")))),(0,t.mdx)("p",null,"Additionally, you can configure how to create or update the cluster:"),(0,t.mdx)("ul",null,(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Default config: run setup commands, restart Ray and use\nthe config cache if available"),(0,t.mdx)("pre",{parentName:"li"},(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"hydra.launcher.create_update_cluster.no_restart=false\nhydra.launcher.create_update_cluster.restart_only=false\nhydra.launcher.create_update_cluster.no_config_cache=false\n"))),(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Skip restarting Ray services when updating the cluster config"),(0,t.mdx)("pre",{parentName:"li"},(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"hydra.launcher.create_update_cluster.no_restart=true\n"))),(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Skip running setup commands and only restart Ray (cannot be used with\n",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra.launcher.create_update_cluster.no_restart"),")"),(0,t.mdx)("pre",{parentName:"li"},(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"hydra.launcher.create_update_cluster.restart_only=true\n"))),(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Fully resolve all environment settings from the cloud provider again"),(0,t.mdx)("pre",{parentName:"li"},(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"hydra.launcher.create_update_cluster.no_config_cache=true\n")))),(0,t.mdx)("h5",{id:"configure-ray-logging"},"Configure Ray Logging"),(0,t.mdx)("p",null,"You can manage Ray specific logging by configuring the flags provided by the plugin:"),(0,t.mdx)("ul",null,(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Default config: use minimal verbosity and automatically\ndetect whether to use pretty-print and color mode"),(0,t.mdx)("pre",{parentName:"li"},(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},'hydra.launcher.logging.log_style="auto"\nhydra.launcher.logging.color_mode="auto"\nhydra.launcher.logging.verbosity=0\n'))),(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Disable pretty-print"),(0,t.mdx)("pre",{parentName:"li"},(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},'hydra.launcher.logging.log_style="record"\n'))),(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Disable color mode"),(0,t.mdx)("pre",{parentName:"li"},(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},'hydra.launcher.logging.color_mode="false"\n'))),(0,t.mdx)("li",{parentName:"ul"},(0,t.mdx)("p",{parentName:"li"},"Increase Ray logging verbosity"),(0,t.mdx)("pre",{parentName:"li"},(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"hydra.launcher.logging.verbosity=3\n")))),(0,t.mdx)("h3",{id:"ray-launcher"},(0,t.mdx)("inlineCode",{parentName:"h3"},"ray")," launcher"),(0,t.mdx)("p",null,(0,t.mdx)("inlineCode",{parentName:"p"},"ray")," launcher lets you launch application on your ray cluster or local machine. You can easily config how your jobs are executed by changing ",(0,t.mdx)("inlineCode",{parentName:"p"},"ray")," launcher's configuration here\n",(0,t.mdx)("inlineCode",{parentName:"p"},"~/hydra/plugins/hydra_ray_launcher/hydra_plugins/hydra_ray_launcher/conf/hydra/launcher/ray.yaml")),(0,t.mdx)("p",null," The ",(0,t.mdx)(l.A,{to:"plugins/hydra_ray_launcher/examples/simple",mdxType:"GithubLink"},"example application")," starts a new ray cluster."),(0,t.mdx)("pre",null,(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"$ python my_app.py  --multirun hydra/launcher=ray\n[HYDRA] Ray Launcher is launching 1 jobs, sweep output dir: multirun/2020-11-10/15-16-28\n[HYDRA] Initializing ray with config: {}\nINFO services.py:1164 -- View the Ray dashboard at http://127.0.0.1:8266\n[HYDRA]        #0 : \n(pid=97801) [__main__][INFO] - Executing task 1\n")),(0,t.mdx)("p",null,"You can run the example application on your existing ray cluster as well by overriding ",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra.launcher.ray.init.address"),":"),(0,t.mdx)("pre",null,(0,t.mdx)("code",{parentName:"pre",className:"language-commandline"},"$ python my_app.py  --multirun hydra/launcher=ray hydra.launcher.ray.init.address=localhost:6379\n[HYDRA] Ray Launcher is launching 1 jobs, sweep output dir: multirun/2020-11-10/15-13-32\n[HYDRA] Initializing ray with config: {'num_cpus': None, 'num_gpus': None, 'address': 'localhost:6379'}\nINFO worker.py:633 -- Connecting to existing Ray cluster at address: 10.30.99.17:6379\n[HYDRA]        #0 : \n(pid=93358) [__main__][INFO] - Executing task 1\n")),(0,t.mdx)("h3",{id:"configure-rayinit-and-rayremote"},"Configure ",(0,t.mdx)("inlineCode",{parentName:"h3"},"ray.init()")," and ",(0,t.mdx)("inlineCode",{parentName:"h3"},"ray.remote()")),(0,t.mdx)("p",null,"Ray launcher is built on top of ",(0,t.mdx)("a",{parentName:"p",href:"https://docs.ray.io/en/master/package-ref.html?highlight=ray.remote#ray-init"},(0,t.mdx)("inlineCode",{parentName:"a"},"ray.init()")),"\nand ",(0,t.mdx)("a",{parentName:"p",href:"https://docs.ray.io/en/master/package-ref.html?highlight=ray.remote#ray-remote"},(0,t.mdx)("inlineCode",{parentName:"a"},"ray.remote()")),".\nYou can configure ",(0,t.mdx)("inlineCode",{parentName:"p"},"ray")," by overriding ",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra.launcher.ray.init")," and ",(0,t.mdx)("inlineCode",{parentName:"p"},"hydra.launcher.ray.remote"),".\nCheck out an ",(0,t.mdx)(l.A,{to:"plugins/hydra_ray_launcher/examples/simple/config.yaml",mdxType:"GithubLink"},"example config"),"."))}u.isMDXComponent=!0},49595:(e,n,a)=>{a.d(n,{A:()=>m,C:()=>p});var r=a(58168),t=a(96540),l=a(75489),i=a(44586),o=a(48295);function d(e){const n=(0,o.ir)();return(0,i.default)().siteConfig.customFields.githubLinkVersionToBaseUrl[n?.name??"current"]+e}function m(e){return t.createElement(l.default,(0,r.A)({},e,{to:d(e.to),target:"_blank"}))}function p(e){const n=e.text??"Example (Click Here)";return t.createElement(m,e,t.createElement("span",null,"\xa0"),t.createElement("img",{src:"https://img.shields.io/badge/-"+n+"-informational",alt:"Example (Click Here)"}))}}}]);